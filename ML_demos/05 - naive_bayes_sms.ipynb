{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Example\n",
    "\n",
    "Using an SMS Spam data set (slightly modified) from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). The data set is a collection of 5574 SMS messages that have been labeled as ham or spam. The file is a tab-delimited file with the first column the label and the second the message content. I edited the data set to remove some unwanted columns and add headings. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows and columns: (4837, 2)\n",
      "   spam                                               text\n",
      "0     0  Go until jurong point, crazy.. Available only ...\n",
      "1     0                      Ok lar... Joking wif u oni...\n",
      "2     1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3     0  U dun say so early hor... U c already then say...\n",
      "4     0  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('sms-spam.csv', header=0, usecols=[1,2], encoding='latin-1')\n",
    "print('rows and columns:', df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Text preprocessing\n",
    "\n",
    "Before applying a machine learning algorithm, we need to do some preprocessing on the text. The following code removes stop words while creating a tf-idf representation of the data.\n",
    "\n",
    "The TfidfVectorizer is a combination of two other sklearn functions: CountVectorizer, and TfidfTransformer. \n",
    "\n",
    "There are too many parameters to list here, [refer to the doc](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "\n",
    "An excellent primer on sklearn text processing [is found here]()http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set up X and y\n",
    "X = vectorizer.fit_transform(df.text)\n",
    "y = df.spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a peek at X\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     1\n",
       "3     0\n",
       "4     0\n",
       "5     1\n",
       "6     0\n",
       "7     0\n",
       "8     1\n",
       "9     1\n",
       "10    0\n",
       "11    1\n",
       "12    1\n",
       "13    0\n",
       "14    0\n",
       "15    1\n",
       "16    0\n",
       "17    0\n",
       "18    0\n",
       "19    1\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at y\n",
    "y[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and test sets\n",
    "\n",
    "First we need to establish that our predictor column is the text column and the label we are trying to learn is our target column. Then we split the data into train and test sets, with 20% of the data going to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (3869, 8613)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8, random_state=1234)\n",
    "\n",
    "# take a peek at the data\n",
    "print('train size:', X_train.shape)\n",
    "X_train.toarray()[:5]\n",
    "\n",
    "# this is a very sparse matrix because most of the 8613 words don't occur in each sms message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train the naive bayes classifier\n",
    "\n",
    "For this data, let's try the MultinomialNB. \n",
    "\n",
    "We used the default settings. You should always research the documentation and see what these mean:\n",
    "\n",
    "- alpha: additive (Laplace) smoothing (0 for no smoothing)\n",
    "- fit_prior: if True, learn priors from data; if false, use a uniform prior\n",
    "- class_prior: lets you specify class priors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "### evaluate on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[848,   0],\n",
       "       [ 32,  88]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# make predictions on the test data\n",
    "pred = naive_bayes.predict(X_test)\n",
    "\n",
    "# print confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848 0 32 88\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix has this form for our example, where \"negative\" means not spam:\n",
    "#     tn   fp\n",
    "#     fn   tp\n",
    "\n",
    "# breaking down the confusion matrix to understand terminology\n",
    "# not_spam = 0, the negative class\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(tn, fp, fn, tp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.96694214876\n",
      "precision score:  1.0\n",
      "recall score:  0.733333333333\n",
      "f1 score:  0.846153846154\n"
     ]
    }
   ],
   "source": [
    "print('accuracy score: ', accuracy_score(y_test, pred))\n",
    "print('precision score: ', precision_score(y_test, pred))\n",
    "print('recall score: ', recall_score(y_test, pred))\n",
    "print('f1 score: ', f1_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "In our example, spam = 1, not-spam = 0. Spam is the \"positive\" class.\n",
    "\n",
    "#### precision\n",
    "\n",
    "Precision measures what proportion of our spam classifications was correct.\n",
    "\n",
    "Precision = tp / (tp + fp)\n",
    "\n",
    "If you have no false positives, you get 100% precision.\n",
    "\n",
    "#### recall\n",
    "\n",
    "Recall measures what proportion of spam messages were correctly identifed.\n",
    "\n",
    "Recall = tp / (tp + fn)\n",
    "\n",
    "We got 88 / (88 + 32) = .73 recall\n",
    "\n",
    "#### f1 - the geometric mean\n",
    "\n",
    "f1 = 2pr / (p + r) = 2 * 1 * 73 / (1 + .73) = .84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How good is our accuracy?\n",
    "\n",
    "In the data set, there are 4199 not-spam messages out of 4837. The test data distribution is similar. So if we guess not spam every time we would have 87% accuracy. It seems that Naive Bayes did learn something. The accuracy was several points above this simple baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam size in test data: 848\n",
      "test size:  968\n",
      "0.8760330578512396\n"
     ]
    }
   ],
   "source": [
    "print('spam size in test data:',y_test[y_test==0].shape[0])\n",
    "print('test size: ', len(y_test))\n",
    "baseline = y_test[y_test==0].shape[0] / y_test.shape[0] \n",
    "print(baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine some wrong classificataions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4179    1\n",
       "677     1\n",
       "2073    1\n",
       "2466    1\n",
       "4721    1\n",
       "3144    1\n",
       "1788    1\n",
       "801     1\n",
       "511     1\n",
       "4062    1\n",
       "4731    1\n",
       "1150    1\n",
       "2754    1\n",
       "924     1\n",
       "444     1\n",
       "1583    1\n",
       "4757    1\n",
       "760     1\n",
       "165     1\n",
       "4214    1\n",
       "1266    1\n",
       "851     1\n",
       "827     1\n",
       "2932    1\n",
       "3003    1\n",
       "4635    1\n",
       "4363    1\n",
       "1558    1\n",
       "366     1\n",
       "3528    1\n",
       "4479    1\n",
       "2584    1\n",
       "Name: spam, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[y_test != pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam                                                    1\n",
      "text    CALL 09090900040 & LISTEN TO EXTREME DIRTY LIV...\n",
      "Name: 1536, dtype: object\n",
      "spam                                                    1\n",
      "text    Santa Calling! Would your little ones like a c...\n",
      "Name: 4692, dtype: object\n",
      "spam                                                    1\n",
      "text    You have 1 new voicemail. Please call 08719181...\n",
      "Name: 2915, dtype: object\n",
      "spam                                                    1\n",
      "text    INTERFLORA - ÂIt's not too late to order Inte...\n",
      "Name: 2464, dtype: object\n",
      "spam                                                    1\n",
      "text    CLAIRE here am havin borin time & am now alone...\n",
      "Name: 1101, dtype: object\n",
      "spam                                                    1\n",
      "text    500 free text msgs. Just text ok to 80488 and ...\n",
      "Name: 1268, dtype: object\n",
      "spam                                                    1\n",
      "text    Will u meet ur dream partner soon? Is ur caree...\n",
      "Name: 227, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for i in [1536, 4692, 2915, 2464, 1101, 1268, 227]:\n",
    "    print(df.loc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### analysis\n",
    "\n",
    "There are capital letters and exclamation points in these messages that were misclassified as not spam, but they really are spam.  The way we preprocessed got rid of this information so our algorithm could not learn from it. \n",
    "\n",
    "Will we get better performance if we process the data differently?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Second Try\n",
    "\n",
    "Let's preprocess the text differently to recognize punctuation and caps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam                                                    1\n",
      "text     caps   num  &  caps   caps   caps   caps   ca...\n",
      "Name: 1536, dtype: object\n",
      "spam                                                    1\n",
      "text    Santa Calling! Would your little ones like a c...\n",
      "Name: 4692, dtype: object\n",
      "spam                                               1\n",
      "text    You have 1 new voicemail. Please call  num .\n",
      "Name: 2915, dtype: object\n",
      "spam                                                    1\n",
      "text     caps  - ÂIt's not too late to order Interflo...\n",
      "Name: 2464, dtype: object\n",
      "spam                                                    1\n",
      "text     caps  here am havin borin time & am now alone...\n",
      "Name: 1101, dtype: object\n",
      "spam                                                    1\n",
      "text     num  free text msgs. Just text ok to  num  an...\n",
      "Name: 1268, dtype: object\n",
      "spam                                                    1\n",
      "text    Will u meet ur dream partner soon? Is ur caree...\n",
      "Name: 227, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "df['text'].replace('[\\d][\\d]+', ' num ', regex=True, inplace=True)\n",
    "df['text'].replace('[!@#*][!@#*]+', ' punct ', regex=True, inplace=True)\n",
    "df['text'].replace('[A-Z][A-Z]+', ' caps ', regex=True, inplace=True)\n",
    "    \n",
    "# these are known problem messages \n",
    "for i in [1536, 4692, 2915, 2464, 1101, 1268, 227]:\n",
    "    print(df.loc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do the rest of the processing\n",
    "\n",
    "X = vectorizer.fit_transform(df.text)\n",
    "y = df.spam\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8, random_state=1234)\n",
    "\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.979338842975\n",
      "precision score:  1.0\n",
      "recall score:  0.833333333333\n",
      "f1 score:  0.909090909091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[848,   0],\n",
       "       [ 20, 100]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate\n",
    "\n",
    "pred = naive_bayes.predict(X_test)\n",
    "print('accuracy score: ', accuracy_score(y_test, pred))\n",
    "print('precision score: ', precision_score(y_test, pred))\n",
    "print('recall score: ', recall_score(y_test, pred))\n",
    "print('f1 score: ', f1_score(y_test, pred))\n",
    "confusion_matrix(y_test, pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that we moved 12 observations that were misclassified as not-spam into spam. We got better recall which in turn led to a better f1 score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
