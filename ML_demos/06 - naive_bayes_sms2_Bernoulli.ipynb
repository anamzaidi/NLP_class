{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Example, revisited\n",
    "\n",
    "This is a repeat of the previous ML demo, using the same sms data. We will use the BournoulliNB algorithm instead of the MultinomialNB model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows and columns: (4837, 2)\n",
      "   spam                                               text\n",
      "0     0  Go until jurong point, crazy.. Available only ...\n",
      "1     0                      Ok lar... Joking wif u oni...\n",
      "2     1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3     0  U dun say so early hor... U c already then say...\n",
      "4     0  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('sms-spam.csv', header=0, usecols=[1,2], encoding='latin-1')\n",
    "print('rows and columns:', df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook we saw that we got better results by identifying punctuation and all caps, so let's do that again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "df['text'].replace('[\\d][\\d]+', ' num ', regex=True, inplace=True)\n",
    "df['text'].replace('[!@#*][!@#*]+', ' punct ', regex=True, inplace=True)\n",
    "df['text'].replace('[A-Z][A-Z]+', ' caps ', regex=True, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preprocessing\n",
    "\n",
    "Before applying a machine learning algorithm, we need to do some preprocessing on the text. The following code removes stop words while creating a tf-idf representation of the data.\n",
    "\n",
    "We changed a few settings on the vectorizer. We let binary=True which will set tf=1 instead of using counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up X and y\n",
    "X = vectorizer.fit_transform(df.text)\n",
    "y = df.spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and test sets\n",
    "\n",
    "First we need to establish that our predictor column is the text column and the label we are trying to learn is our target column. Then we split the data into train and test sets, with 20% of the data going to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8, random_state=1234)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train the naive bayes classifier\n",
    "\n",
    "For this data, let's try the BernoulliNB instead of MultinomialNB. The BernoulliNB function will convert our data to binary features.\n",
    "\n",
    "We used the default settings. You should always research the documentation and see what these mean:\n",
    "\n",
    "- alpha: additive (Laplace) smoothing (0 for no smoothing)\n",
    "- binarize: threshold for mapping input features to booleans; if None, input is assumed to be binary vectors\n",
    "- fit_prior: if True, learn priors from data; if false, use a uniform prior\n",
    "- class_prior: lets you specify class priors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "naive_bayes = BernoulliNB()\n",
    "naive_bayes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "### evaluate on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[847,   1],\n",
       "       [ 13, 107]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions on the test data\n",
    "pred = naive_bayes.predict(X_test)\n",
    "\n",
    "# print confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847 1 13 107\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix has this form for our example, where \"negative\" means not spam:\n",
    "#     tn   fp\n",
    "#     fn   tp\n",
    "\n",
    "# breaking down the confusion matrix to understand terminology\n",
    "# not_spam = 0, the negative class\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, pred).ravel()\n",
    "print(tn, fp, fn, tp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.985537190083\n",
      "precision score:  0.990740740741\n",
      "recall score:  0.891666666667\n",
      "f1 score:  0.938596491228\n"
     ]
    }
   ],
   "source": [
    "print('accuracy score: ', accuracy_score(y_test, pred))\n",
    "print('precision score: ', precision_score(y_test, pred))\n",
    "print('recall score: ', recall_score(y_test, pred))\n",
    "print('f1 score: ', f1_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analysis\n",
    "\n",
    "How did the BernoulliNB model with binarized vectors do compared to the MultinomialNB model with count vectors?\n",
    "\n",
    "The accuracy was slightly higher, precision very slightly lower but recall jumped from .83 to .89. This made our f1 score .9385, over 3 points higher than the MultinomialNB model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
